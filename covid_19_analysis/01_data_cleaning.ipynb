{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 01. Data Cleaning and Inspection\n",
                "\n",
                "This notebook loads all available datasets, inspects them for quality issues (missing values, duplicates), and prepares them for analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "data_dir = \"../archive\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading country_wise_latest.csv...\n",
                        "  Shape: (187, 15)\n",
                        "Loading covid_19_clean_complete.csv...\n",
                        "  Shape: (49068, 10)\n",
                        "Loading day_wise.csv...\n",
                        "  Shape: (188, 12)\n",
                        "Loading full_grouped.csv...\n",
                        "  Shape: (35156, 10)\n",
                        "Loading usa_county_wise.csv...\n",
                        "  Shape: (627920, 14)\n",
                        "Loading worldometer_data.csv...\n",
                        "  Shape: (209, 16)\n"
                    ]
                }
            ],
            "source": [
                "files = {\n",
                "    \"country_wise\": \"country_wise_latest.csv\",\n",
                "    \"covid_clean\": \"covid_19_clean_complete.csv\",\n",
                "    \"day_wise\": \"day_wise.csv\",\n",
                "    \"full_grouped\": \"full_grouped.csv\",\n",
                "    \"usa_county\": \"usa_county_wise.csv\",\n",
                "    \"worldometer\": \"worldometer_data.csv\"\n",
                "}\n",
                "\n",
                "dfs = {}\n",
                "for name, filename in files.items():\n",
                "    print(f\"Loading {filename}...\")\n",
                "    dfs[name] = pd.read_csv(os.path.join(data_dir, filename))\n",
                "    print(f\"  Shape: {dfs[name].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Inspect for Missing Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- country_wise Missing Values ---\n",
                        "Series([], dtype: int64)\n",
                        "\n",
                        "--- covid_clean Missing Values ---\n",
                        "Province/State    34404\n",
                        "dtype: int64\n",
                        "\n",
                        "--- day_wise Missing Values ---\n",
                        "Series([], dtype: int64)\n",
                        "\n",
                        "--- full_grouped Missing Values ---\n",
                        "Series([], dtype: int64)\n",
                        "\n",
                        "--- usa_county Missing Values ---\n",
                        "FIPS      1880\n",
                        "Admin2    1128\n",
                        "dtype: int64\n",
                        "\n",
                        "--- worldometer Missing Values ---\n",
                        "Continent             1\n",
                        "Population            1\n",
                        "NewCases            205\n",
                        "TotalDeaths          21\n",
                        "NewDeaths           206\n",
                        "TotalRecovered        4\n",
                        "NewRecovered        206\n",
                        "ActiveCases           4\n",
                        "Serious,Critical     87\n",
                        "Tot Cases/1M pop      1\n",
                        "Deaths/1M pop        22\n",
                        "TotalTests           18\n",
                        "Tests/1M pop         18\n",
                        "WHO Region           25\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "for name, df in dfs.items():\n",
                "    print(f\"\\n--- {name} Missing Values ---\")\n",
                "    missing = df.isnull().sum()\n",
                "    print(missing[missing > 0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Date Standardization\n",
                "Convert 'Date' columns to datetime objects where applicable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Converting Date column in covid_clean...\n",
                        "  Date range: 2020-01-22 00:00:00 to 2020-07-27 00:00:00\n",
                        "Converting Date column in day_wise...\n",
                        "  Date range: 2020-01-22 00:00:00 to 2020-07-27 00:00:00\n",
                        "Converting Date column in full_grouped...\n",
                        "  Date range: 2020-01-22 00:00:00 to 2020-07-27 00:00:00\n",
                        "Converting Date column in usa_county...\n",
                        "  Date range: 2020-01-22 00:00:00 to 2020-07-27 00:00:00\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_7212/982914456.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
                        "  df['Date'] = pd.to_datetime(df['Date'])\n"
                    ]
                }
            ],
            "source": [
                "for name, df in dfs.items():\n",
                "    if 'Date' in df.columns:\n",
                "        print(f\"Converting Date column in {name}...\")\n",
                "        df['Date'] = pd.to_datetime(df['Date'])\n",
                "        print(f\"  Date range: {df['Date'].min()} to {df['Date'].max()}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
